{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script compares the impact of increasing the number of edges in random small world graphs. Since the theoretical motivation behind our approach relies on graphins, we expect that increasing the density of edges will hinder the performance. In addition, our proposed method is compared with other baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "\n",
    "import utils\n",
    "import spectral_nti as snti\n",
    "\n",
    "# %matplotlib qt\n",
    "\n",
    "SEED = 0\n",
    "N_CPUS = cpu_count()\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(id, models, KK, iters):\n",
    "    L_hat = np.zeros((N, N, len(models), len(KK)))\n",
    "    lamd_hat = np.zeros((N, len(models), len(KK)))\n",
    "    Ls = np.zeros((N, N, len(KK)))\n",
    "    lamds = np.zeros((N, len(KK)))\n",
    "    cs_err = np.zeros((len(models), len(KK)))\n",
    "    for i, k in enumerate(KK):\n",
    "        # Create graphs\n",
    "        A0 = nx.to_numpy_array(nx.watts_strogatz_graph(N0, k, p, seed=SEED))\n",
    "        L0 = np.diag(np.sum(A0, 0)) - A0\n",
    "        lambdas0, _ = np.linalg.eigh(L0)\n",
    "\n",
    "        A = nx.to_numpy_array(nx.watts_strogatz_graph(N, k, p))\n",
    "        Ls[:,:,i] = np.diag(np.sum(A, 0)) - A\n",
    "        lamds[:,i], V = np.linalg.eigh(Ls[:,:,i])\n",
    "\n",
    "        for j, model in enumerate(models):\n",
    "            if model['name'] in ['MGL-Tr', 'MGL-Sq', 'MGL-Heat', 'MGL-Poly']:\n",
    "                model['cs'], cs_err[j,i] = utils.compute_cs(model['gs'], lambdas0, lamds[:,i])\n",
    "            elif model['name'] == 'MGL-Tr=1':\n",
    "                model['cs'] = 1\n",
    "\n",
    "        # Create signals\n",
    "        X = utils.create_signals(Ls[:,:,i], M)\n",
    "        C_hat = X@X.T/M\n",
    "\n",
    "        # Estimate graph\n",
    "        for j, model in enumerate(models):\n",
    "            t = time.time()\n",
    "            L_hat[:,:,j,i], lamd_hat[:,j,i] = utils.est_graph(C_hat, model, iters)\n",
    "            t = time.time() - t\n",
    "            print('Graph-{}, k-{}: Model: {} - cs: {:.4f} - Time(sec): {:.3}'.\n",
    "                  format(id, k, model['name'], cs_err[j,i], t))\n",
    "    return L_hat, lamd_hat, Ls, lamds, cs_err\n",
    "\n",
    "\n",
    "def est_errs1(Ls, lamds, L_hat, lams_hat, sq_err=True):\n",
    "    err_lamb = np.zeros(lams_hat.shape[1:])\n",
    "    err_L = np.zeros(L_hat.shape[2:])\n",
    "    for k in range(L_hat.shape[-1]):\n",
    "        for i in range(L_hat.shape[-2]):\n",
    "            L = Ls[:,:,i,k]\n",
    "            lamd = lamds[:,i,k]\n",
    "            norm_L = np.linalg.norm(L, 'fro')\n",
    "            norm_lam = np.linalg.norm(lamd, 2)\n",
    "\n",
    "            for j in range(L_hat.shape[-3]):\n",
    "                err_L[j,i,k] = np.linalg.norm(L-L_hat[:,:,j,i,k], 'fro')/norm_L\n",
    "                err_lamb[j,i,k] = np.linalg.norm(lamd-lams_hat[:,j,i,k], 2)/norm_lam\n",
    "\n",
    "                if sq_err:\n",
    "                    err_L[j,i,k] = err_L[j,i,k]**2\n",
    "                    err_lamb[j,i,k] = err_lamb[j,i,k]**2\n",
    "\n",
    "    return err_L, err_lamb\n",
    "\n",
    "\n",
    "def est_errs2(Ls, lamds, L_hat, lams_hat, sq_err=True):\n",
    "    err_lamb = np.zeros(lams_hat.shape[1:])\n",
    "    err_L = np.zeros(L_hat.shape[2:])\n",
    "    for k in range(L_hat.shape[-1]):\n",
    "        for i in range(L_hat.shape[-2]):\n",
    "            L = Ls[:,:,i,k]\n",
    "            lamd = lamds[:,i,k]\n",
    "            norm_L = np.linalg.norm(L, 'fro')\n",
    "            norm_lam = np.linalg.norm(lamd, 2)\n",
    "\n",
    "            for j in range(L_hat.shape[-3]):\n",
    "                if np.all((L_hat[:,:,j,i,k] == 0)):\n",
    "                    norm_L_hat = 1\n",
    "                    norm_lam_hat = 1\n",
    "                else:\n",
    "                    norm_L_hat = np.linalg.norm(L_hat[:,:,j,i,k], 'fro')\n",
    "                    norm_lam_hat = np.linalg.norm(lams_hat[:,j,i,k], 2)\n",
    "\n",
    "                L_hat_norm = L_hat[:,:,j,i,k]/norm_L_hat\n",
    "                lam_hat_norm = lams_hat[:,j,i,k]/norm_lam_hat\n",
    "                err_L[j,i,k] = np.linalg.norm(L/norm_L-L_hat_norm,'fro')\n",
    "                err_lamb[j,i,k] = np.linalg.norm(lamd/norm_lam-lam_hat_norm, 2)\n",
    "\n",
    "                if sq_err:\n",
    "                    err_L[j,i,k] = err_L[j,i,k]**2\n",
    "                    err_lamb[j,i,k] = err_lamb[j,i,k]**2\n",
    "\n",
    "    return err_L, err_lamb\n",
    "\n",
    "\n",
    "def plot_err(KK, models, err, ylab, semlogy=True, ylim=[]):\n",
    "    plt.figure()\n",
    "    for i, model in enumerate(models):\n",
    "        if semlogy:\n",
    "            plt.semilogy(KK, err[i,:], model['fmt'], label=model['name'],\n",
    "                        linewidth=2, markersize=12)\n",
    "        else:\n",
    "            plt.plot(KK, err[i,:], model['fmt'], label=model['name'],\n",
    "                     linewidth=2, markersize=12)\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Mean node degree')\n",
    "        plt.ylabel(ylab)\n",
    "        plt.legend()\n",
    "        plt.xlim([KK[0], KK[-1]])\n",
    "        if ylim:\n",
    "            plt.ylim(ylim)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph params\n",
    "p = .1\n",
    "N0 = 150\n",
    "N = 100\n",
    "M = 500\n",
    "\n",
    "n_graphs = 50\n",
    "KK = [8, 12, 16, 20, 24, 28, 32, 36, 40]\n",
    "iters = 200\n",
    "\n",
    "GS = [\n",
    "    lambda a, b : cp.sum(a)/b,    # delta: 4e-2\n",
    "    lambda a, b : cp.sum(a**2)/b,  # delta: .7\n",
    "    lambda a, b : cp.sum(cp.exp(-a))/b,    # delta: 3e-3\n",
    "    lambda a, b : cp.sum(.25*a**2-.75*a)/b,\n",
    "]\n",
    "BOUNDS = [\n",
    "    lambda lamd, lamd_t, b : -2/b*lamd_t.T@lamd,\n",
    "    lambda lamd, lamd_t, b : 1/b*cp.exp(-lamd_t).T@lamd,\n",
    "    lambda lamd, lamd_t, b: 1/b*(0.75-2*0.25*lamd_t).T@lamd,\n",
    "]\n",
    "\n",
    "deltas = [1e-3, .3, .005, .1]\n",
    "\n",
    "models = [\n",
    "    # Baselines\n",
    "    {'name': 'GLasso', 'alpha': 0.01, 'fmt': '^-'},\n",
    "    {'name': 'SGL', 'fmt': '*--', 'regs': {'alpha': 0, 'beta': 25, 'c1': .1, 'c2': 30, 'conn_comp': 1}},\n",
    "    {'name': 'MGL-Tr=1', 'gs': GS[0], 'bounds': [], 'fmt': '2--',\n",
    "     'regs': {'alpha': 0, 'beta': .9, 'gamma': 0, 'deltas': deltas[0]}},\n",
    "\n",
    "    # Our algorithms\n",
    "    {'name': 'MGL-Tr', 'gs': GS[0], 'bounds': [], 'fmt': '2-',\n",
    "     'regs': {'alpha': 0, 'beta': 5, 'gamma': 0, 'deltas': deltas[0]}},\n",
    "    {'name': 'MGL-Sq', 'gs': GS[1], 'bounds': BOUNDS[0], 'fmt': 'o-',\n",
    "     'regs': {'alpha': 0, 'beta': 25, 'gamma': 50, 'deltas': deltas[1]}},\n",
    "    {'name': 'MGL-Heat', 'gs': GS[2], 'bounds': BOUNDS[1], 'fmt': 'x-',\n",
    "     'regs': {'alpha': 0, 'beta': 10, 'gamma': 100, 'deltas': deltas[2]}},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CPUS: 12\n",
      "----- 60.227008028825125  mins -----\n"
     ]
    }
   ],
   "source": [
    "# Estimate graph\n",
    "total_t = time.time()\n",
    "Ls = np.zeros((N, N, len(KK), n_graphs))\n",
    "lamds = np.zeros((N, len(KK), n_graphs))\n",
    "Ls_hat = np.zeros((N, N, len(models), len(KK), n_graphs))\n",
    "lamds_hat = np.zeros((N, len(models), len(KK), n_graphs))\n",
    "cs_err = np.zeros((len(models), len(KK), n_graphs))\n",
    "print('N_CPUS:', N_CPUS)\n",
    "pool = Parallel(n_jobs=N_CPUS, verbose=0)\n",
    "resps = pool(delayed(run_exp)(i, models, KK, iters) for i in range(n_graphs))\n",
    "\n",
    "for i, resp in enumerate(resps):\n",
    "    Ls_hat[:,:,:,:,i], lamds_hat[:,:,:,i], Ls[:,:,:,i], \\\n",
    "        lamds[:,:,i], cs_err[:,:,i] = resp\n",
    "\n",
    "total_t = time.time() - total_t\n",
    "print('-----', total_t/60, ' mins -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_L, err_lamb = est_errs2(Ls, lamds, Ls_hat, lamds_hat)\n",
    "# mean_cs_err = np.abs(np.mean(cs_err, 2))\n",
    "mean_err_L = np.median(err_L, 2)\n",
    "mean_err_lam = np.mean(err_lamb, 2)\n",
    "# plot_err(KK, models, mean_cs_err, 'Mean cs err', semlogy=True)\n",
    "plot_err(KK, models, mean_err_L, 'Mean Err2 L')\n",
    "plot_err(KK, models, mean_err_lam, 'Mean Err2 lambdas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_L, _ = est_errs1(Ls, lamds, Ls_hat, lamds_hat)\n",
    "mean_err_L = np.median(err_L, 2)\n",
    "plot_err(KK, models, mean_err_L, 'Mean Err1 L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data\n",
    "# models_aux = [{'name': model['name'], 'fmt': model['fmt'], 'regs': model['regs']}\n",
    "#                 for model in models]\n",
    "# data = {\n",
    "#     'Ls': Ls,\n",
    "#     'lamds': lamds,\n",
    "#     'Ls_hat': Ls_hat,\n",
    "#     'lamds_hat': lamds_hat,\n",
    "#     'cs_err': cs_err,\n",
    "#     'KK': KK,\n",
    "#     'iters' : iters,\n",
    "#     'models': models_aux\n",
    "# }\n",
    "# file = 'density_{}graphs_{}iters'.format(n_graphs, iters)\n",
    "# np.save('results/graph_density/' + file, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data\n",
    "%matplotlib qt\n",
    "file = 'results/graph_density/density_50graphs_200iters_weighted.npy'\n",
    "data = np.load(file, allow_pickle=True).item()\n",
    "models = data['models']\n",
    "\n",
    "Ls = data['Ls']\n",
    "lamds = data['lamds']\n",
    "Ls_hat = data['Ls_hat']\n",
    "lamds_hat = data['lamds_hat']\n",
    "KK = data['KK']\n",
    "iters = data['iters']\n",
    "models = data['models']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
