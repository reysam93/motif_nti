{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script compares the impact of inaccuracies in the reference graph. More specifically, we consider an SBM with no edges between nodes on different communities as the true graph, and for the reference graph, we progressively increase the probability of edges between nodes in different communities to check how the difference affects the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "\n",
    "import utils\n",
    "\n",
    "# %matplotlib qt\n",
    "\n",
    "SEED = 0\n",
    "N_CPUS = cpu_count()\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(id, models, QQ0, iters):\n",
    "    # Create graph\n",
    "    A = nx.to_numpy_array(nx.random_partition_graph(block_sizes, p, q))\n",
    "    L = np.diag(np.sum(A, 0)) - A\n",
    "    lamds, _ = np.linalg.eigh(L)\n",
    "\n",
    "    # Create covariance\n",
    "    X = utils.create_signals(L, M)\n",
    "    C_hat = X@X.T/M\n",
    "\n",
    "    L_hat = np.zeros((N, N, len(models), len(QQ0)))\n",
    "    lamd_hat = np.zeros((N, len(models), len(QQ0)))\n",
    "    cs_err = np.zeros((len(models), len(QQ0)))\n",
    "    for i, q0 in enumerate(QQ0):\n",
    "        # Create reference graph\n",
    "        A0 = nx.to_numpy_array(nx.random_partition_graph(block_sizes0, p, q0))\n",
    "        L0 = np.diag(np.sum(A0, 0)) - A0\n",
    "        lambdas0, _ = np.linalg.eigh(L0)\n",
    "\n",
    "        for j, model in enumerate(models):\n",
    "            if model['name'] == 'MGL-Tr=1':\n",
    "                model['cs'] = 1\n",
    "            elif 'gs' in model.keys():\n",
    "                model['cs'], cs_err[j,i] = utils.compute_cs(model['gs'], lambdas0, lamds)\n",
    "\n",
    "            t = time.time()\n",
    "            L_hat[:,:,j,i], lamd_hat[:,j,i] = utils.est_graph(C_hat, model, iters)\n",
    "            t = time.time() - t\n",
    "            print('Graph-{}, q0-{}: Model: {} - cs: {:.4f} - Time(sec): {:.3}'.\n",
    "                  format(id, q0, model['name'], cs_err[j,i], t))\n",
    "    return L_hat, lamd_hat, L, lamds, cs_err\n",
    "\n",
    "\n",
    "def est_errs1(Ls, lamds, L_hat, lams_hat, sq_err=True):\n",
    "    err_lamb = np.zeros(lams_hat.shape[1:])\n",
    "    err_L = np.zeros(L_hat.shape[2:])\n",
    "    for k in range(L_hat.shape[-1]):\n",
    "        L = Ls[:,:,k]\n",
    "        lamd = lamds[:,k]\n",
    "        norm_L = np.linalg.norm(L, 'fro')\n",
    "        norm_lam = np.linalg.norm(lamd, 2)\n",
    "\n",
    "        for i in range(L_hat.shape[-2]):\n",
    "            for j in range(L_hat.shape[-3]):\n",
    "                err_L[j,i,k] = np.linalg.norm(L-L_hat[:,:,j,i,k], 'fro')/norm_L\n",
    "                err_lamb[j,i,k] = np.linalg.norm(lamd-lams_hat[:,j,i,k], 2)/norm_lam\n",
    "\n",
    "                if sq_err:\n",
    "                    err_L[j,i,k] = err_L[j,i,k]**2\n",
    "                    err_lamb[j,i,k] = err_lamb[j,i,k]**2\n",
    "\n",
    "    return err_L, err_lamb\n",
    "\n",
    "\n",
    "def est_errs2(Ls, lamds, L_hat, lams_hat, sq_err=True):\n",
    "    err_lamb = np.zeros(lams_hat.shape[1:])\n",
    "    err_L = np.zeros(L_hat.shape[2:])\n",
    "    for k in range(L_hat.shape[-1]):\n",
    "        L = Ls[:,:,k]\n",
    "        lamd = lamds[:,k]\n",
    "        norm_L = np.linalg.norm(L, 'fro')\n",
    "        norm_lam = np.linalg.norm(lamd, 2)\n",
    "\n",
    "        for i in range(L_hat.shape[-2]):\n",
    "            for j in range(L_hat.shape[-3]):\n",
    "                if np.all((L_hat[:,:,j,i,k] == 0)):\n",
    "                    norm_L_hat = 1\n",
    "                    norm_lam_hat = 1\n",
    "                else:\n",
    "                    norm_L_hat = np.linalg.norm(L_hat[:,:,j,i,k], 'fro')\n",
    "                    norm_lam_hat = np.linalg.norm(lams_hat[:,j,i,k], 2)\n",
    "\n",
    "                L_hat_norm = L_hat[:,:,j,i,k]/norm_L_hat\n",
    "                lam_hat_norm = lams_hat[:,j,i,k]/norm_lam_hat\n",
    "                err_L[j,i,k] = np.linalg.norm(L/norm_L-L_hat_norm,'fro')\n",
    "                err_lamb[j,i,k] = np.linalg.norm(lamd/norm_lam-lam_hat_norm, 2)\n",
    "\n",
    "                if sq_err:\n",
    "                    err_L[j,i,k] = err_L[j,i,k]**2\n",
    "                    err_lamb[j,i,k] = err_lamb[j,i,k]**2\n",
    "\n",
    "    return err_L, err_lamb\n",
    "\n",
    "\n",
    "def plot_err(QQ, models, err, ylab, logy=True, ylim=[]):\n",
    "    plt.figure()\n",
    "    for i, model in enumerate(models):\n",
    "        if logy:\n",
    "            plt.loglog(QQ, err[i,:], model['fmt'], label=model['name'],\n",
    "                        linewidth=2, markersize=12)\n",
    "        else:\n",
    "            plt.semilogx(QQ, err[i,:], model['fmt'], label=model['name'],\n",
    "                         linewidth=2, markersize=12)\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Inter-cluster edge prob')\n",
    "        plt.ylabel(ylab)\n",
    "        plt.legend()\n",
    "        plt.xlim([QQ[0], QQ[-1]])\n",
    "        if ylim:\n",
    "            plt.ylim(ylim)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment variables\n",
    "QQ0 = [1e-4, 5e-4, .001, .005, .01, .05, .1, .5]\n",
    "M = 1000\n",
    "n_graphs = 50\n",
    "iters = 200\n",
    "\n",
    "# Graph parameters\n",
    "K = 5\n",
    "block_sizes0 = [30]*K\n",
    "block_sizes = [20]*K\n",
    "p = .3\n",
    "q = 0\n",
    "N0 = sum(block_sizes0)\n",
    "N = sum(block_sizes)   \n",
    "\n",
    "GS = [\n",
    "    lambda a, b : cp.sum(a)/b,    # delta: 4e-2\n",
    "    lambda a, b : cp.sum(a**2)/b,  # delta: .7\n",
    "    lambda a, b : cp.sum(cp.exp(-a))/b,    # delta: 3e-3\n",
    "    lambda a, b : cp.sum(.25*a**2-.75*a)/b,\n",
    "]\n",
    "BOUNDS = [\n",
    "    lambda lamd, lamd_t, b : -2/b*lamd_t.T@lamd,\n",
    "    lambda lamd, lamd_t, b : 1/b*cp.exp(-lamd_t).T@lamd,\n",
    "    lambda lamd, lamd_t, b: 1/b*(0.75-2*0.25*lamd_t).T@lamd,\n",
    "]\n",
    "\n",
    "deltas = [.7, 10, .003, 3]\n",
    "\n",
    "# regs M=1000\n",
    "models = [\n",
    "    # Baselines\n",
    "    # {'name': 'Pinv', 'fmt': 'v-'},\n",
    "    # {'name': 'GLasso', 'alpha': 0.01, 'fmt': '^-'},\n",
    "    {'name': 'MGL-Tr=1', 'gs': GS[0], 'bounds': [], 'fmt': '2--',\n",
    "     'regs': {'alpha': 0, 'beta': 0.2, 'gamma': 0, 'deltas': deltas[0]}},\n",
    "    {'name': 'SGL', 'fmt': '*--', 'regs': {'alpha': 0, 'beta': .2, 'c1': 1, 'c2': 20, 'conn_comp': K}},\n",
    "    # {'name': 'Unc', 'gs': [], 'bounds': [], 'cs': [], 'fmt': '1--',\n",
    "    #  'regs': {'alpha': .005, 'beta': 1, 'gamma': 0, 'deltas': deltas[0]}},\n",
    "\n",
    "    # Our algorithms\n",
    "    {'name': 'MGL-Tr', 'gs': GS[0], 'bounds': [], 'fmt': '2-',\n",
    "     'regs': {'alpha': 0, 'beta': .2, 'gamma': 0, 'deltas': deltas[0]}},\n",
    "    {'name': 'MGL-Sq', 'gs': GS[1], 'bounds': BOUNDS[0], 'fmt': 'o-',\n",
    "     'regs': {'alpha': 0, 'beta': .2, 'gamma': 500, 'deltas': deltas[1]}},\n",
    "    {'name': 'MGL-Heat', 'gs': GS[2], 'bounds': BOUNDS[1], 'fmt': 'x-',\n",
    "     'regs': {'alpha': .5, 'beta': 1, 'gamma': 10, 'deltas': deltas[2]}},\n",
    "    {'name': 'MGL-Poly', 'gs': GS[3], 'bounds': BOUNDS[2], 'fmt': 's-',\n",
    "     'regs': {'alpha': 0, 'beta': .3, 'gamma': 1000, 'deltas': deltas[3]}},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CPUS: 12\n",
      "----- 2.459053556124369  mins -----\n"
     ]
    }
   ],
   "source": [
    "total_t = time.time()\n",
    "Ls = np.zeros((N, N, n_graphs))\n",
    "lamds = np.zeros((N, n_graphs))\n",
    "Ls_hat = np.zeros((N, N, len(models), len(QQ0), n_graphs))\n",
    "lamds_hat = np.zeros((N, len(models), len(QQ0), n_graphs))\n",
    "cs_err = np.zeros((len(models), len(QQ0), n_graphs))\n",
    "\n",
    "print('N_CPUS:', N_CPUS)\n",
    "pool = Parallel(n_jobs=N_CPUS, verbose=0)\n",
    "resps = pool(delayed(run_exp)(i, models, QQ0, iters) for i in range(n_graphs))\n",
    "\n",
    "for i, resp in enumerate(resps):\n",
    "    Ls_hat[:,:,:,:,i], lamds_hat[:,:,:,i], Ls[:,:,i], \\\n",
    "        lamds[:,i], cs_err[:,:,i] = resp\n",
    "\n",
    "total_t = time.time() - total_t\n",
    "print('-----', total_t/60, ' mins -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SGL (4,)\n",
      "1 MGL-Tr (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-f44dbdd0611b>:102: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 MGL-Sq (4,)\n",
      "3 MGL-Heat (4,)\n",
      "0 SGL (4,)\n",
      "1 MGL-Tr (4,)\n",
      "2 MGL-Sq (4,)\n",
      "3 MGL-Heat (4,)\n",
      "0 SGL (4,)\n",
      "1 MGL-Tr (4,)\n",
      "2 MGL-Sq (4,)\n",
      "3 MGL-Heat (4,)\n"
     ]
    }
   ],
   "source": [
    "err_L, err_lamb = est_errs2(Ls, lamds, Ls_hat, lamds_hat)\n",
    "mean_cs_err = np.abs(np.mean(cs_err, 2))\n",
    "mean_err_L = np.median(err_L, 2)\n",
    "mean_err_lam = np.mean(err_lamb, 2)\n",
    "plot_err(QQ0, models, mean_cs_err, 'Mean cs err', logy=True)\n",
    "plot_err(QQ0, models, mean_err_L, 'Mean Err2 L')\n",
    "plot_err(QQ0, models, mean_err_lam, 'Mean Err2 lambdas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SGL (4,)\n",
      "1 MGL-Tr (4,)\n",
      "2 MGL-Sq (4,)\n",
      "3 MGL-Heat (4,)\n"
     ]
    }
   ],
   "source": [
    "err_L, _ = est_errs1(Ls, lamds, Ls_hat, lamds_hat)\n",
    "mean_err_L = np.median(err_L, 2)\n",
    "plot_err(QQ0, models, mean_err_L, 'Mean Err1 L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data\n",
    "# models_aux = [{'name': model['name'], 'fmt': model['fmt'], 'regs': \\\n",
    "#                model['regs'] if 'regs' in model.keys() else {}} \n",
    "#                for model in models]\n",
    "# data = {\n",
    "#     'Ls': Ls,\n",
    "#     'lamds': lamds,\n",
    "#     'Ls_hat': Ls_hat,\n",
    "#     'lamds_hat': lamds_hat,\n",
    "#     'cs_err': cs_err,\n",
    "#     'KK': KK,\n",
    "#     'iters' : iters,\n",
    "#     'models': models_aux,\n",
    "#     'M': M,\n",
    "# }\n",
    "# file = 'density_{}graphs_{}iters_{}M'.format(n_graphs, iters, M)\n",
    "# np.save('results/graph_density/' + file, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data\n",
    "# %matplotlib qt\n",
    "# file = 'results/graph_density/density_50graphs_200iters_1000M.npy'\n",
    "# data = np.load(file, allow_pickle=True).item()\n",
    "# models = data['models']\n",
    "\n",
    "# Ls = data['Ls']\n",
    "# lamds = data['lamds']\n",
    "# Ls_hat = data['Ls_hat']\n",
    "# lamds_hat = data['lamds_hat']\n",
    "# KK = data['KK']\n",
    "# iters = data['iters']\n",
    "# models = data['models']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
