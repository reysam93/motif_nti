{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script compares the impact of inaccuracies in the reference graph. More specifically, we consider an SBM with no edges between nodes on different communities as the true graph, and for the reference graph, we progressively increase the probability of edges between nodes in different communities to check how the difference affects the performance. Graph of sizes N=100 and N=150 are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "\n",
    "import utils\n",
    "\n",
    "# %matplotlib qt\n",
    "\n",
    "SEED = 0\n",
    "N_CPUS = cpu_count()\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(id, models, QQ0, block_sizes, iters):\n",
    "    # Create graph\n",
    "    A = nx.to_numpy_array(nx.random_partition_graph(block_sizes, p, q))\n",
    "    L = np.diag(np.sum(A, 0)) - A\n",
    "    lamds, _ = np.linalg.eigh(L)\n",
    "    N = lamds.shape[0]\n",
    "\n",
    "    # Create covariance\n",
    "    X = utils.create_signals(L, M)\n",
    "    C_hat = X@X.T/M\n",
    "\n",
    "    L_hat = np.zeros((N, N, len(models), len(QQ0)))\n",
    "    lamd_hat = np.zeros((N, len(models), len(QQ0)))\n",
    "    cs_err = np.zeros((len(models), len(QQ0)))\n",
    "    for i, q0 in enumerate(QQ0):\n",
    "        # Create reference graph\n",
    "        A0 = nx.to_numpy_array(nx.random_partition_graph(block_sizes0, p, q0))\n",
    "        L0 = np.diag(np.sum(A0, 0)) - A0\n",
    "        lambdas0, _ = np.linalg.eigh(L0)\n",
    "\n",
    "        for j, model in enumerate(models):\n",
    "            if model['name'] == 'MGL-Tr=1':\n",
    "                model['cs'] = 1\n",
    "            elif 'gs' in model.keys() and model['gs']:\n",
    "                model['cs'], cs_err[j,i] = utils.compute_cs(model['gs'], lambdas0, lamds)\n",
    "                cs_err[j,i] /= model['cs']\n",
    "\n",
    "            t = time.time()\n",
    "            L_hat[:,:,j,i], lamd_hat[:,j,i] = utils.est_graph(C_hat, model, iters)\n",
    "            t = time.time() - t\n",
    "            print('Graph-{}, q0-{}: Model: {} - cs: {:.4f} - N: {} - Time(sec): {:.3}'.\n",
    "                  format(id, q0, model['name'], cs_err[j,i], N, t))\n",
    "    return L_hat, lamd_hat, L, lamds, cs_err\n",
    "\n",
    "\n",
    "def est_errs1(Ls, lamds, L_hat, lams_hat, sq_err=True):\n",
    "    err_lamb = np.zeros(lams_hat.shape[1:])\n",
    "    err_L = np.zeros(L_hat.shape[2:])\n",
    "    for k in range(L_hat.shape[-1]):\n",
    "        L = Ls[:,:,k]\n",
    "        lamd = lamds[:,k]\n",
    "        norm_L = np.linalg.norm(L, 'fro')\n",
    "        norm_lam = np.linalg.norm(lamd, 2)\n",
    "\n",
    "        for i in range(L_hat.shape[-2]):\n",
    "            for j in range(L_hat.shape[-3]):\n",
    "                err_L[j,i,k] = np.linalg.norm(L-L_hat[:,:,j,i,k], 'fro')/norm_L\n",
    "                err_lamb[j,i,k] = np.linalg.norm(lamd-lams_hat[:,j,i,k], 2)/norm_lam\n",
    "\n",
    "                if sq_err:\n",
    "                    err_L[j,i,k] = err_L[j,i,k]**2\n",
    "                    err_lamb[j,i,k] = err_lamb[j,i,k]**2\n",
    "\n",
    "    return err_L, err_lamb\n",
    "\n",
    "\n",
    "def est_errs2(Ls, lamds, L_hat, lams_hat, sq_err=True):\n",
    "    err_lamb = np.zeros(lams_hat.shape[1:])\n",
    "    err_L = np.zeros(L_hat.shape[2:])\n",
    "    for k in range(L_hat.shape[-1]):\n",
    "        L = Ls[:,:,k]\n",
    "        lamd = lamds[:,k]\n",
    "        norm_L = np.linalg.norm(L, 'fro')\n",
    "        norm_lam = np.linalg.norm(lamd, 2)\n",
    "\n",
    "        for i in range(L_hat.shape[-2]):\n",
    "            for j in range(L_hat.shape[-3]):\n",
    "                if np.all((L_hat[:,:,j,i,k] == 0)):\n",
    "                    norm_L_hat = 1\n",
    "                    norm_lam_hat = 1\n",
    "                else:\n",
    "                    norm_L_hat = np.linalg.norm(L_hat[:,:,j,i,k], 'fro')\n",
    "                    norm_lam_hat = np.linalg.norm(lams_hat[:,j,i,k], 2)\n",
    "\n",
    "                L_hat_norm = L_hat[:,:,j,i,k]/norm_L_hat\n",
    "                lam_hat_norm = lams_hat[:,j,i,k]/norm_lam_hat\n",
    "                err_L[j,i,k] = np.linalg.norm(L/norm_L-L_hat_norm,'fro')\n",
    "                err_lamb[j,i,k] = np.linalg.norm(lamd/norm_lam-lam_hat_norm, 2)\n",
    "\n",
    "                if sq_err:\n",
    "                    err_L[j,i,k] = err_L[j,i,k]**2\n",
    "                    err_lamb[j,i,k] = err_lamb[j,i,k]**2\n",
    "\n",
    "    return err_L, err_lamb\n",
    "\n",
    "\n",
    "def plot_err(QQ, model_list, err_list, N_list, ylab, logy=True, ylim=[], skip=[]):\n",
    "    plt.figure()\n",
    "    for j, models in enumerate(model_list):\n",
    "\n",
    "        err = err_list[j]\n",
    "        for i, model in enumerate(models):\n",
    "            if i in skip:\n",
    "                continue\n",
    "\n",
    "            leg = '{}, N={}'.format(model['name'], N_list[j])\n",
    "            if logy:\n",
    "                plt.loglog(QQ, err[i,:], model['fmt'], label=leg,\n",
    "                            linewidth=2, markersize=12)\n",
    "            else:\n",
    "                plt.semilogx(QQ, err[i,:], model['fmt'], label=leg,\n",
    "                            linewidth=2, markersize=12)\n",
    "                            \n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Inter-cluster edge prob')\n",
    "    plt.ylabel(ylab)\n",
    "    plt.legend()\n",
    "    plt.xlim([QQ[0], QQ[-1]])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment variables\n",
    "QQ0 = np.logspace(-3, np.log10(.5), 10)  # [1e-3, .01, .1,]  #\n",
    "M = 1000\n",
    "n_graphs = 100\n",
    "iters = 200\n",
    "\n",
    "# Graph parameters\n",
    "K = 5\n",
    "block_sizes0 = [30]*K\n",
    "block_sizes1 = [20]*K\n",
    "block_sizes2 = [30]*K\n",
    "p = .3\n",
    "q = 0\n",
    "\n",
    "N0 = sum(block_sizes0)\n",
    "N1 = sum(block_sizes1)\n",
    "N2 = sum(block_sizes2)\n",
    "\n",
    "GS = [\n",
    "    lambda a, b : cp.sum(a)/b,\n",
    "    lambda a, b : cp.sum(a**2)/b,\n",
    "    lambda a, b : cp.sum(cp.exp(-a))/b,\n",
    "    lambda a, b : cp.sum(.25*a**2-.75*a)/b,\n",
    "]\n",
    "BOUNDS = [\n",
    "    lambda lamd, lamd_t, b : -2/b*lamd_t.T@lamd,\n",
    "    lambda lamd, lamd_t, b : 1/b*cp.exp(-lamd_t).T@lamd,\n",
    "    lambda lamd, lamd_t, b: 1/b*(0.75-2*0.25*lamd_t).T@lamd,\n",
    "]\n",
    "\n",
    "# N=100\n",
    "deltas1 = [2.9, 45, .06, 11]\n",
    "models1 = [\n",
    "    # Baselines\n",
    "    # {'name': 'MGL-Tr=1', 'gs': GS[0], 'bounds': [], 'fmt': 'x-',\n",
    "    #  'regs': {'alpha': 0, 'beta': 0.4, 'gamma': 0, 'deltas': 1e-4}},\n",
    "    {'name': 'SGL', 'fmt': '*-', 'regs': {'alpha': .05, 'beta': .7, 'c1': 1, 'c2': 20, 'conn_comp': K}},\n",
    "    # Our algorithms\n",
    "    {'name': 'MGL-Tr', 'gs': GS[0], 'bounds': [], 'fmt': 'o-',\n",
    "     'regs': {'alpha': 0, 'beta': .2, 'gamma': 0, 'deltas': deltas1[0]}},\n",
    "    {'name': 'MGL-Poly', 'gs': GS[3], 'bounds': BOUNDS[2], 'fmt': 's-',\n",
    "     'regs': {'alpha': 0, 'beta': .3, 'gamma': 1000, 'deltas': deltas1[3]}},\n",
    "]\n",
    "\n",
    "# N=150\n",
    "deltas2 = [.7, 10, .003, 3]\n",
    "models2 = [\n",
    "    # Baselines\n",
    "    # {'name': 'MGL-Tr=1', 'gs': GS[0], 'bounds': [], 'fmt': 'x--',\n",
    "    #  'regs': {'alpha': 0, 'beta': 0.4, 'gamma': 0, 'deltas': 1e-4}},\n",
    "    {'name': 'SGL', 'fmt': '*--', 'regs': {'alpha': 0, 'beta': .2, 'c1': 1, 'c2': 20, 'conn_comp': K}},\n",
    "    # Our algorithms\n",
    "    {'name': 'MGL-Tr', 'gs': GS[0], 'bounds': [], 'fmt': 'o--',\n",
    "     'regs': {'alpha': 0, 'beta': .2, 'gamma': 0, 'deltas': deltas2[0]}},\n",
    "    {'name': 'MGL-Poly', 'gs': GS[3], 'bounds': BOUNDS[2], 'fmt': 's--',\n",
    "     'regs': {'alpha': 0, 'beta': .3, 'gamma': 1000, 'deltas': deltas2[3]}},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate graphs N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CPUS: 12\n",
      "----- 32.0432119290034  mins -----\n"
     ]
    }
   ],
   "source": [
    "total_t = time.time()\n",
    "Ls1 = np.zeros((N1, N1, n_graphs))\n",
    "lamds1 = np.zeros((N1, n_graphs))\n",
    "Ls_hat1 = np.zeros((N1, N1, len(models1), len(QQ0), n_graphs))\n",
    "lamds_hat1 = np.zeros((N1, len(models1), len(QQ0), n_graphs))\n",
    "cs_err1 = np.zeros((len(models1), len(QQ0), n_graphs))\n",
    "\n",
    "print('N_CPUS:', N_CPUS)\n",
    "pool = Parallel(n_jobs=N_CPUS, verbose=0)\n",
    "resps = pool(delayed(run_exp)(i, models1, QQ0, block_sizes1, iters) for i in range(n_graphs))\n",
    "\n",
    "for i, resp in enumerate(resps):\n",
    "    Ls_hat1[:,:,:,:,i], lamds_hat1[:,:,:,i], Ls1[:,:,i], \\\n",
    "        lamds1[:,i], cs_err1[:,:,i] = resp\n",
    "\n",
    "total_t = time.time() - total_t\n",
    "print('-----', total_t/60, ' mins -----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate graphs N=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_CPUS: 12\n",
      "----- 56.22063890695572  mins -----\n"
     ]
    }
   ],
   "source": [
    "total_t = time.time()\n",
    "Ls2 = np.zeros((N2, N2, n_graphs))\n",
    "lamds2 = np.zeros((N2, n_graphs))\n",
    "Ls_hat2 = np.zeros((N2, N2, len(models2), len(QQ0), n_graphs))\n",
    "lamds_hat2 = np.zeros((N2, len(models2), len(QQ0), n_graphs))\n",
    "cs_err2 = np.zeros((len(models2), len(QQ0), n_graphs))\n",
    "\n",
    "print('N_CPUS:', N_CPUS)\n",
    "pool = Parallel(n_jobs=N_CPUS, verbose=0)\n",
    "resps = pool(delayed(run_exp)(i, models2, QQ0, block_sizes2, iters) for i in range(n_graphs))\n",
    "\n",
    "for i, resp in enumerate(resps):\n",
    "    Ls_hat2[:,:,:,:,i], lamds_hat2[:,:,:,i], Ls2[:,:,i], \\\n",
    "        lamds2[:,i], cs_err2[:,:,i] = resp\n",
    "\n",
    "total_t = time.time() - total_t\n",
    "print('-----', total_t/60, ' mins -----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "model_list = [models1, models2]\n",
    "N_list = [N1, N2]\n",
    "\n",
    "err_L1, err_lamb1 = est_errs2(Ls1, lamds1, Ls_hat1, lamds_hat1)\n",
    "err_L2, err_lamb2 = est_errs2(Ls2, lamds2, Ls_hat2, lamds_hat2)\n",
    "\n",
    "# mean_cs_err1 = np.abs(np.mean(cs_err1, 2))\n",
    "# mean_cs_err2 = np.abs(np.mean(cs_err2, 2))\n",
    "# cs_err_list = [mean_cs_err1, mean_cs_err2]\n",
    "# plot_err(QQ0, model_list, cs_err_list, N_list, 'Noralized Mean cs err', logy=True)\n",
    "\n",
    "mean_err_L1 = np.median(err_L1, 2)\n",
    "mean_err_L2 = np.median(err_L2, 2)\n",
    "err_L_list = [mean_err_L1, mean_err_L2]\n",
    "plot_err(QQ0, model_list, err_L_list, N_list, 'Mean Err(L,L*)', logy=True)\n",
    "\n",
    "# mean_err_lam1 = np.mean(err_lamb1, 2)\n",
    "# mean_err_lam2 = np.mean(err_lamb2, 2)\n",
    "# err_lam_list = [mean_err_lam1, mean_err_lam2]\n",
    "# plot_err(QQ0, model_list, err_lam_list, N_list, 'Mean Err2 lambdas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_L1, err_lamb1 = est_errs1(Ls1, lamds1, Ls_hat1, lamds_hat1)\n",
    "err_L2, err_lamb2 = est_errs1(Ls2, lamds2, Ls_hat2, lamds_hat2)\n",
    "mean_err_L1 = np.median(err_L1, 2)\n",
    "mean_err_L2 = np.median(err_L2, 2)\n",
    "err_L_list = [mean_err_L1, mean_err_L2]\n",
    "plot_err(QQ0, model_list, err_L_list, N_list, 'Mean Err1 L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data\n",
    "# models1_aux = [{'name': model['name'], 'fmt': model['fmt'], 'regs': \\\n",
    "#                model['regs'] if 'regs' in model.keys() else {}} \n",
    "#                for model in models1]\n",
    "# models2_aux = [{'name': model['name'], 'fmt': model['fmt'], 'regs': \\\n",
    "#                model['regs'] if 'regs' in model.keys() else {}} \n",
    "#                for model in models2]\n",
    "# data = {\n",
    "#     'Ls1': Ls1,\n",
    "#     'lamds1': lamds1,\n",
    "#     'Ls_hat1': Ls_hat1,\n",
    "#     'lamds_hat1': lamds_hat1,\n",
    "#     'cs_err1': cs_err1,\n",
    "#     'models1': models1_aux,\n",
    "#     'Ls2': Ls2,\n",
    "#     'lamds2': lamds2,\n",
    "#     'Ls_hat2': Ls_hat2,\n",
    "#     'lamds_hat2': lamds_hat2,\n",
    "#     'cs_err2': cs_err2,\n",
    "#     'models2': models2_aux,\n",
    "#     'QQ0': QQ0,\n",
    "#     'iters' : iters,\n",
    "    \n",
    "#     'M': M,\n",
    "# }\n",
    "# file = 'ref-errs_{}graphs_{}iters_{}M'.format(n_graphs, iters, M)\n",
    "# np.save('results/ref_graph_errs/' + file, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Ls1', 'lamds1', 'Ls_hat1', 'lamds_hat1', 'cs_err1', 'models', 'Ls2', 'lamds2', 'Ls_hat2', 'lamds_hat2', 'cs_err2', 'QQ0', 'iters', 'M'])\n"
     ]
    }
   ],
   "source": [
    "# Load OLD data\n",
    "# %matplotlib qt\n",
    "# file = 'results/ref_graph_errs/ref-errs_50graphs_200iters_1000M_150N.npy'\n",
    "# file = 'results/ref_graph_errs/ref-errs_50graphs_200iters_1000M.npy'\n",
    "# data = np.load(file, allow_pickle=True).item()\n",
    "# models = data['models']\n",
    "\n",
    "# Ls = data['Ls']\n",
    "# lamds = data['lamds']\n",
    "# Ls_hat = data['Ls_hat']\n",
    "# lamds_hat = data['lamds_hat']\n",
    "# QQ0 = data['QQ0']\n",
    "# iters = data['iters']\n",
    "# models = data['models']\n",
    "# M = data['M']\n",
    "# cs_err = data['cs_err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Ls1', 'lamds1', 'Ls_hat1', 'lamds_hat1', 'cs_err1', 'models', 'Ls2', 'lamds2', 'Ls_hat2', 'lamds_hat2', 'cs_err2', 'QQ0', 'iters', 'M'])\n"
     ]
    }
   ],
   "source": [
    "# Load NEW data\n",
    "# %matplotlib qt\n",
    "file = 'results/ref_graph_errs/ref-errs_50graphs_200iters_1000M.npy'\n",
    "data = np.load(file, allow_pickle=True).item()\n",
    "\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "models1 = data['models1']\n",
    "Ls1 = data['Ls1']\n",
    "lamds1 = data['lamds1']\n",
    "Ls_hat1 = data['Ls_hat1']\n",
    "lamds_hat1 = data['lamds_hat1']\n",
    "cs_err1 = data['cs_err1']\n",
    "Ls2 = data['Ls2']\n",
    "lamds2 = data['lamds2']\n",
    "Ls_hat2 = data['Ls_hat2']\n",
    "lamds_hat2 = data['lamds_hat2']\n",
    "cs_err2 = data['cs_err2']\n",
    "QQ0 = data['QQ0']\n",
    "iters = data['iters']\n",
    "models2 = data['models2']\n",
    "M = data['M']\n",
    "\n",
    "# Excluding non-plotted data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
